version: '3.8'

services:
  # PostgreSQL Database - Metadata DB + Data Warehouse
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-airflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-airflow}
      POSTGRES_DB: ${POSTGRES_DB:-airflow}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - airflow-network

  # Redis - Message Broker for Celery
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - airflow-network

  # Airflow Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-webserver
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - AIRFLOW_HOME=/opt/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__UNIT_TEST_MODE=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres:5432/${POSTGRES_DB:-airflow}
      - AIRFLOW__CORE__PARALLELISM=4
      - AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=3
      - AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflow
      - AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config
      - ./logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - airflow-network

  # Airflow Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-scheduler
    depends_on:
      postgres:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    environment:
      - AIRFLOW_HOME=/opt/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__UNIT_TEST_MODE=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres:5432/${POSTGRES_DB:-airflow}
      - AIRFLOW__CORE__PARALLELISM=4
      - AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=3
      - AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1
      - AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config
      - ./logs:/opt/airflow/logs
    command: scheduler
    networks:
      - airflow-network

  # Airflow Init - Initialize Database
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW_HOME=/opt/airflow
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres:5432/${POSTGRES_DB:-airflow}
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflow
    command: >
      bash -c "airflow db upgrade &&
               airflow users create --firstname Admin --lastname User --username airflow --password airflow --role Admin --email admin@example.com || true"
    networks:
      - airflow-network

  # Flower - Celery Monitoring (Optional, for future CeleryExecutor)
  flower:
    image: mher/flower:2.0
    container_name: flower
    depends_on:
      - redis
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
    ports:
      - "5555:5555"
    command: celery --broker=redis://redis:6379/0 flower
    networks:
      - airflow-network

volumes:
  postgres_data:
    driver: local

networks:
  airflow-network:
    driver: bridge
